{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.datasets.mldata import fetch_mldata\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "data = mnist['data']\n",
    "labels= mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.RandomState(0).choice(70000, 11000, replace = False)\n",
    "train = data[idx[:10000], :].astype(int)\n",
    "train_labels = labels[idx[:10000]]\n",
    "test = data[idx[10000:], :].astype(int)\n",
    "test_labels = labels[idx[10000:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Implementation of k-NN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_dist(x,y):   \n",
    "    '''euclidian dist between x and y'''\n",
    "    return np.sum(np.power(x-y,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_neighbors_index(q, mat, k):\n",
    "    '''get q_image, train data and k parameter returns k nearest images`  indexes '''\n",
    "    dist = []\n",
    "    for x in mat:\n",
    "        toAdd = euclidean_dist(q,x)\n",
    "        dist.append(toAdd)\n",
    "    dist = np.array(dist)\n",
    "    # sort distance by their index, thus returns the k nearest indexes\n",
    "    dist = np.argsort(dist)[:k]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_index(labels):\n",
    "    ''' create tuples of (label, count) sorted by the counter'''\n",
    "    ind = np.unique(labels, return_counts=True)\n",
    "    pairs = zip(ind[0], ind[1])\n",
    "    pairs.sort(key=operator.itemgetter(1))\n",
    "    return pairs.pop()[0]\n",
    "# return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_model_gen(images, labels_vec, q_image, k):\n",
    "    '''gets training set, labels of the training set, questionable image and k\n",
    "    returns the closest label to the questionable image'''\n",
    "    # get k nearest indexes\n",
    "    ind = k_neighbors_index(q_image, images, k)\n",
    "    neigh_label = labels_vec[ind]\n",
    "    # aggregate to create a dictionary of <label, instances>\n",
    "    return label_index(neigh_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Run k-NN on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the prediction is  0.868\n"
     ]
    }
   ],
   "source": [
    "def knn_single(n=1000, k=10, train, train_labels, test, test_labels):\n",
    "\n",
    "    train_set = images[:n,]\n",
    "    train_set_labels = train_labels[:n]\n",
    "    loss =0\n",
    "    for row in range(0,len(test)):\n",
    "        test_labels[row]\n",
    "        pred = knn_model_gen(train_set, train_set_labels, test[row], k)\n",
    "        if test_labels[row] != pred:\n",
    "            loss +=1\n",
    "    acc = round(1.0-loss*1.0/len(test),5)\n",
    "    print 'the accuracy of the prediction is ', acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A completely random predictor will predict according to the proportion of the labels.  \n",
    "We can see in the following cell that the labels in our training set are approximatly uniform distributed.  \n",
    "Thus, a random predictor will cause in 90% bad prediction, which means accuracy of ~10%.  \n",
    "The KNN predictor acts pretty much the same and has no major advantage over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64),\n",
       " array([ 950, 1082,  985, 1009,  974,  965,  970, 1026,  995, 1044], dtype=int64))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Plotting the accuracy as a function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:38<00:00, 13.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def loss_on_k(k_min = 1, k_max=100, n=1000, train, train_labels, test, test_labels):\n",
    "    '''predict on k_min to k_max the knn algorithm, return a dictionary for each k the amount of mistakes it made'''\n",
    "    k_loss = {}\n",
    "    images=train[:n]\n",
    "    k_range = xrange(k_max, k_min-1, -1)\n",
    "    for row in range(0,len(test)):\n",
    "        # create one time the k nearest images, and each iteration take the needed first k\n",
    "        k_list = k_neighbors_index(test[row], images, k_max)\n",
    "        for k in k_range:\n",
    "            closest_ind = k_list[:k]\n",
    "            best= label_index(train_labels[closest_ind])\n",
    "            if test_labels[row] != best:\n",
    "                if k_loss.has_key(k):\n",
    "                    k_loss[k] +=1\n",
    "                else:\n",
    "                    k_loss[k] = 1\n",
    "    return k_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x9dd6f60>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13de1dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def acc_plot(k_loss):\n",
    "    acc = list(k_loss.values())\n",
    "    k_vals = list(k_loss)\n",
    "    acc = map(lambda x:1.0-x*1.0/len(test),acc)\n",
    "    ax = plt.plot(k_vals, acc, '--')\n",
    "    plt.xlabel('k values')\n",
    "    plt.ylabel('accuracy')\n",
    "    print 'best accuracy is ', round(max(acc),3),  'with k = ',acc.index(max(acc))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy is  0.877 with k =  3\n"
     ]
    }
   ],
   "source": [
    "print 'best accuracy is ', round(max(acc),3),  'with k = ',acc.index(max(acc))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Plotting accuracy as a function of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [14:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took  840.845999956  seconds\n"
     ]
    }
   ],
   "source": [
    "# k_best = acc.index(max(acc))+1\n",
    "def loss_on_n(k_best = 5, n_max = 5000, n_min = 100, train, train_labels, test, test_labels):\n",
    "    n_loss = {}\n",
    "    images=train[:n_max]\n",
    "    n_range = range(n_max, 0, -100)\n",
    "    for row in range(0,len(test)):\n",
    "        # create one time the k nearest per each test sample\n",
    "        k_list = k_neighbors_index(test[row], images[:n_max], n_max)\n",
    "        filtered = k_list\n",
    "        for cur_n in n_range:\n",
    "            if cur_n != n_min: # filter so the k nearest images are existing in the new current training set\n",
    "                filtered = filter(lambda x: x not in range(cur_n-100,cur_n+1),filtered)\n",
    "            closest_ind = filtered[:k_best]\n",
    "            best = label_index(train_labels[closest_ind])\n",
    "            if test_labels[row] != best:\n",
    "                if n_loss.has_key(cur_n):\n",
    "                    n_loss[cur_n] +=1\n",
    "                else:\n",
    "                    n_loss[cur_n] = 1\n",
    "    return n_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc_plot_on_n(n_loss, t_len):\n",
    "    list1, list2 = (list(t) for t in zip(*sorted(zip(list(n_loss), list(n_loss.values())))))\n",
    "    n_vals, acc = (list(t) for t in zip(*sorted(zip(list(n_loss), list(n_loss.values())))))\n",
    "    acc = map(lambda x:1-x*1.0/t_len,acc)\n",
    "    plt.plot(n_vals, acc, '--')\n",
    "    plt.xlabel('n values')\n",
    "    plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_single(train, train_labels, test, test_labels, n=1000, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_loss, k_best, acc = loss_on_k(train, train_labels,test, test_labels)\n",
    "\n",
    "acc_plot(k_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_loss = loss_on_n(train, train_labels, test, test_labels, k_best, n_min = 100, n_max = 5000)\n",
    "\n",
    "acc_plot_on_n(n_loss, t_len=len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
